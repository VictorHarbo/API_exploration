---
title: "API Exploration"
author: "Mikkel Bang Maesen & Victor Harbo Johnston"
date: "9/17/2021"
output: html_document
---
TODO: Write introduction 
TODO: import from API 
TODO: Formulate potential use of data
TODO: Create visuals that can be made from the data
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading libraries
```{r}
library(httr)
library(jsonlite)
library(tidyverse)
library(tidytext)
library(ggwordcloud)
```

## Importing data from the API

https://api.trove.nla.gov.au/v2/result?key=p75vgrks9qi358s0&zone=zone=newspaper&q=danish+AND+immigrant&encoding=json

https://api.trove.nla.gov.au/v2/result?q=danish+AND+immigrant&zone=newspaper&encoding=json&n=100&include=articletext&bulkHarvest=true&s=*
```{r}
### Working for 100 articles
# &include=articletext
#res = GET("https://api.trove.nla.gov.au/v2/result?key=p75vgrks9qi358s0&q=danish+AND+immigrant&zone=newspaper&encoding=xml&n=100&include=articletext")

res = GET("https://api.trove.nla.gov.au/v2/result?key=p75vgrks9qi358s0&q=danish+AND+immigrant&zone=newspaper&encoding=json&n=100&include=articletext&bulkHarvest=true&s=*")
```

## Structuring data
```{r}
data = fromJSON(rawToChar(res$content))
df <- data.frame(data$response$zone$records$article)
df
```
## Counting articles per year
```{r}
years <- format(as.Date(df$date, format="%Y-%m-%d"),"%Y")
tibble(years) -> years
years <- count(years, years)
years %>% 
  ggplot(aes(x = years, y = n)) +
  geom_col(fill="#3399FF", colour="black") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

## Newspapers that mention danish immigrants
```{r}
Newspapers <- count(df, df$title$value)
Newspapers <- rename(Newspapers, newspaper = "df$title$value")
Newspapers <- arrange(Newspapers, desc(n))
Newspapers
```


```{r}
Newspapers %>% 
  top_n(5) %>% 
  ggplot(aes(label = newspaper, size = n, color = n)) +
  geom_text_wordcloud() +
  scale_size_area(max_size = 6) +
  theme_minimal() +
  scale_color_gradient(low = "blue", high = "red")
```
## Most used words in snippets from articles
```{r}
snippets <- data_frame(df$snippet)
snippets <- rename(snippets, text = "df$snippet")
snippets %>% 
  unnest_tokens(word, text) %>% 
  select(word, everything()) -> snippets_tidy

stopwords <- read_csv("stopwords.txt")
snippets_tidy %>% 
  anti_join(stopwords, by = "word") %>% 
  count(word, sort = TRUE) %>% 
  select(word, n) -> snippets_tidy

snippets_tidy
```
```{r}
snippets_tidy %>% 
  top_n(40) %>%
  ggplot(aes(label = word, size = n, color = n)) +
  geom_text_wordcloud() +
  scale_size_area(max_size = 10) +
  theme_minimal() +
  scale_color_gradient(low = "blue", high = "red")
```
## Finding words before and after the word danish
```{r}
stringr::str_extract(df$snippet, "([^\\s]+\\s){5}Danish(\\s[^\\s]+){5}")
```
## Working with the full text of the articles
```{r}
fulltext <- data_frame(df$articleText)
fulltext <- rename(fulltext, text = "df$articleText")
fulltext %>% 
  unnest_tokens(word, text) %>% 
  select(word, everything()) -> fulltext_tidy

stopwords <- read_csv("stopwords.txt")
fulltext_tidy %>% 
  anti_join(stopwords, by = "word") %>% 
  count(word, sort = TRUE) %>% 
  select(word, n) -> fulltext_tidy

fulltext_tidy
```
```{r}
fulltext_tidy %>% 
  top_n(50) %>%
  ggplot(aes(label = word, size = n, color = n)) +
  geom_text_wordcloud() +
  scale_size_area(max_size = 10) +
  theme_minimal() +
  scale_color_gradient(low = "blue", high = "red")
```

